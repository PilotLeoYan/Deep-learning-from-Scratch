{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f07af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "tf.keras.config.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "256a4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_class(Class):  \n",
    "    \"\"\"Register functions as methods in created class.\"\"\"\n",
    "    def wrapper(obj):\n",
    "        setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4507c5",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86a853a",
   "metadata": {},
   "source": [
    "Dataset\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{X} &\\in \\mathbb{R}^{M \\times N} \\\\\n",
    "\\mathbf{y} &\\in \\mathbb{R}^{M}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78a6eef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "(100,)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import random\n",
    "\n",
    "M: int = 100 #number of samples\n",
    "N: int = 4 #number of features\n",
    "\n",
    "TRUE_B = random.random()\n",
    "\n",
    "X, Y, TRUE_W = make_regression(n_samples=M, n_features=N, n_targets=1,\n",
    "                               n_informative=N-1, bias=TRUE_B, noise=1, coef=True)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(TRUE_W.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000c71b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0a72ed",
   "metadata": {},
   "source": [
    "## weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daab31c",
   "metadata": {},
   "source": [
    "Trainables parameters\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{w} &\\in \\mathbb{R}^{N} \\\\\n",
    "b &\\in \\mathbb{R}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac7b8024",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearRegression:\n",
    "    def __init__(self, num_features: int, penalty: float) -> None:\n",
    "        self.w = torch.randn(num_features)\n",
    "        self.b = torch.randn(1)\n",
    "        self.lambd = penalty\n",
    "\n",
    "    def copy_params(self, tf_model) -> None:\n",
    "        \"\"\"Copy the parameters from a TensorFlow model to this PyTorch model.\n",
    "\n",
    "        Args:\n",
    "            tf_model: A TensorFlow model from which to copy the parameters.\n",
    "            penalty: Penalty hyperparemeter for L2 regularization.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.w.copy_(torch.tensor(tf_model.weights[0].numpy()[:,0]))\n",
    "        self.b.copy_(torch.tensor(tf_model.weights[1].numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c084d321",
   "metadata": {},
   "source": [
    "## weighted sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeb79fa",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{\\hat{y}}(\\mathbf{X}) = \\mathbf{X}\\mathbf{w} + b \\\\\n",
    "\\mathbf{\\hat{y}} : \\mathbb{R}^{M \\times N} \\rightarrow \n",
    "\\mathbb{R}^{M}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de7d50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(SimpleLinearRegression)\n",
    "def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Predict the output for input x.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor of shape (n_samples, num_features).\n",
    "\n",
    "    Returns:\n",
    "        y_pred: Predicted output tensor of shape (n_samples,).\n",
    "    \"\"\"\n",
    "    y_pred = torch.matmul(x, self.w) + self.b\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa373d19",
   "metadata": {},
   "source": [
    "## MSE with weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e377633",
   "metadata": {},
   "source": [
    "Loss function: Mean Squared Error with weight decay:\n",
    "$$\n",
    "\\begin{align*}\n",
    "L(\\mathbf{\\hat{y}}) &= \\frac{1}{M} \\sum_{i=1}^{M}(\n",
    "    \\hat{y}_i - \\mathbf{\\mathbb{y}}_i)^{2} \n",
    "+ \\lambda \\sum_{j=0}^{N} w_{j}^{2} \\\\\n",
    "L &: \\mathbb{R}^{M} \\rightarrow \\mathbb{R}\n",
    "\\end{align*}\n",
    "$$\n",
    "Vectorized form:\n",
    "$$\n",
    "\\begin{align*}\n",
    "L(\\mathbf{\\hat{y}}) &= \\frac{1}{M} \n",
    "    \\left\\| \\mathbf{e} \\right\\|_{2}^2 \n",
    "+ \\lambda \\left\\| \\boldsymbol{w} \\right\\|_{2}^{2} \\\\\n",
    "&= \\frac{1}{M} (\\mathbf{e}^T \\mathbf{e}) + \\lambda (\\mathbf{w}^T \\mathbf{w}) \\\\\n",
    "\\mathbf{e} &:= \\mathbf{\\hat{y}} - \\mathbf{y}\n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\lambda$ is called regularization or penalty hyperparameter. <br>\n",
    "**Note**: this type of weight decay is called $\\mathit{L}_2$ Regularization. <br>\n",
    "**Remark**: weight regularization only affect on $\\mathbf{w}$ and not on $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c53d64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(SimpleLinearRegression)\n",
    "def evaluate(self, x: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "    \"\"\"Evaluate the model on input x and target y_true using MSE.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor of shape (n_samples, num_features).\n",
    "        y_true: Target tensor of shape (n_samples,).\n",
    "\n",
    "    Returns:\n",
    "        loss: MSE loss between predictions and true values.\n",
    "    \"\"\"\n",
    "    y_pred = self.predict(x)\n",
    "    e = y_pred - y_true\n",
    "    loss = (e**2).sum()\n",
    "    return loss.item() / len(y_true)\n",
    "\n",
    "@add_to_class(SimpleLinearRegression)\n",
    "def weight_decay_loss(self, x: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "    \"\"\"Evaluate the model on input x and target y_true using MSE with L2 regularization\n",
    "    \n",
    "    Args:\n",
    "        x: Input tensor of shape (n_samples, num_features).\n",
    "        y_true: Target tensor of shape (n_samples,)\n",
    "\n",
    "    Returns:\n",
    "        loss: MSE loss with L2 regularization between predictions and true values.\n",
    "    \"\"\"\n",
    "    loss = self.evaluate(x, y_true)\n",
    "    return loss + self.lambd * (self.w**2).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9628f578",
   "metadata": {},
   "source": [
    "# Gradient with $\\mathit{L}_{2}$ regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643d16a1",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{w}} =\n",
    "\\frac{\\partial}{\\partial \\mathbf{w}} \\left(\n",
    "    {\\color{cyan} \\frac{1}{M} (\\mathbf{e}^T \\mathbf{e})}\n",
    "\\right) \n",
    "+ \\frac{\\partial}{\\partial \\mathbf{w}} \\left(\n",
    "    {\\color{orange} \\lambda (\\mathbf{w}^T \\mathbf{w})}\n",
    "\\right) \\\\\n",
    "$$\n",
    "where the ${\\color{cyan} \\text{cyan part}}$ is the derivative of the original MSE loss function and the ${\\color{orange} \\text{orange part}}$ is the derivative of the regularizer. <br>\n",
    "Therefore\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\mathbf{w}} \\left(\n",
    "    \\frac{1}{M} (\\mathbf{e}^T \\mathbf{e})\n",
    "\\right) = \\frac{2}{M} (\\mathbf{\\hat{y}} - \\mathbf{y}) \\mathbf{X}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\mathbf{w}} \\left(\n",
    "    \\lambda (\\mathbf{w}^T \\mathbf{w})\n",
    "\\right) = 2\\lambda \\mathbf{w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc32789",
   "metadata": {},
   "source": [
    "## summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc3f68b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{w}} =\n",
    "{\\color{cyan} \\frac{2}{M} (\\mathbf{\\hat{y}} - \\mathbf{y}) \\mathbf{X}}\n",
    "+ {\\color{orange} 2\\lambda \\mathbf{w}}\n",
    "$$\n",
    "**Note**: still that $\\frac{\\partial L}{\\partial \\mathbf{w}} \\in \\mathbb{R}^{N}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434f8839",
   "metadata": {},
   "source": [
    "## Parameters update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a199a29d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{w} &\\leftarrow \\mathbf{w} - \\eta \\nabla_{\\mathbf{w}} L =\n",
    "\\mathbf{w} - \\eta \\left(\n",
    "    \\frac{2}{M} (\\mathbf{\\hat{y}} - \\mathbf{y}) \\mathbf{X}\n",
    "    + 2\\lambda \\mathbf{w}\n",
    "\\right) \\\\\n",
    "b &\\leftarrow b - \\eta \\nabla_{b} L =\n",
    "b - \\eta \\left(\n",
    "    \\frac{2}{M} (\\mathbf{\\hat{y}} - \\mathbf{y}) \\boldsymbol{1}\n",
    "\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf504357",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(SimpleLinearRegression)\n",
    "def update(self, x: torch.Tensor, y_true: torch.Tensor,\n",
    "           y_pred: torch.Tensor, lr: float) -> None:\n",
    "    \"\"\"Update the model parameters.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor of shape (n_samples, num_features).\n",
    "        y_true: Target tensor of shape (n_samples,).\n",
    "        y_pred: Predicted output tensor of shape (n_samples,).\n",
    "        lr: Learning rate.\n",
    "    \"\"\"\n",
    "    delta = 2 * (y_pred - y_true) / len(y_true)\n",
    "    self.b -= lr * delta.sum()\n",
    "    self.w -= lr * (torch.matmul(delta, x) + 2 * self.lambd * self.w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b584448d",
   "metadata": {},
   "source": [
    "## Fit (Gradient descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7841483",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(SimpleLinearRegression)\n",
    "def fit(self, x_train: torch.Tensor, y_train: torch.Tensor, \n",
    "        epochs: int, lr: float, batch_size: int, \n",
    "        x_valid: torch.Tensor, y_valid: torch.Tensor) -> None:\n",
    "    \"\"\"fit the model using gradient descent.\n",
    "\n",
    "    Args:\n",
    "        x_train: Input tensor of shape (n_samples, num_features).\n",
    "        y_train: Target tensor of shape (n_samples,).\n",
    "        epochs: Number of epochs to train.\n",
    "        lr: learning rate (0, 1).\n",
    "        batch_size: Int number of batch.\n",
    "        x_valid: Input tensor of shape (n_valid_samples, num_features).\n",
    "        y_valid: Input tensor of shape (n_valid_samples,).\n",
    "    \"\"\"\n",
    "    self.loss_fit = []\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(0, len(y_train), batch_size):\n",
    "            x_b = x_train[batch:batch+batch_size]\n",
    "            y_b = y_train[batch:batch+batch_size]\n",
    "\n",
    "            y_pred = self.predict(x_b)\n",
    "\n",
    "            self.update(x_b, y_b, y_pred, lr)\n",
    "        self.loss_fit.append(self.weight_decay_loss(x_valid, y_valid))\n",
    "        loss_v = round(self.loss_fit[-1], 4)\n",
    "        print(f'epoch: {epoch} - MSE_v: {loss_v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186b36c2",
   "metadata": {},
   "source": [
    "# Scratch vs TF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7757178b",
   "metadata": {},
   "source": [
    "## Train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "511a0e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([85, 4]) torch.Size([85])\n",
      "torch.Size([15, 4]) torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = torch.tensor(X[:85]), torch.tensor(Y[:85])\n",
    "X_valid, Y_valid = torch.tensor(X[85:]), torch.tensor(Y[85:])\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_valid.shape, Y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770577f6",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c5520aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EPOCHS = 6\n",
    "BATCH = len(X_train) // 3\n",
    "LAMBD = 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439927e7",
   "metadata": {},
   "source": [
    "## models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b77ab",
   "metadata": {},
   "source": [
    "### TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37c856b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635ms/step - loss: 855.0676\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> (40.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5\u001b[0m (40.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> (40.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5\u001b[0m (40.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TFModel = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, \n",
    "                          activation='linear',\n",
    "                          kernel_regularizer = tf.keras.regularizers.L2(\n",
    "                              l2=LAMBD\n",
    "                          ))\n",
    "])\n",
    "\n",
    "TFModel.compile(\n",
    "    loss = tf.keras.losses.MSE,\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=LR)\n",
    ")\n",
    "\n",
    "TFModel.evaluate(X[:1], Y[:1])\n",
    "\n",
    "TFModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ce0d06",
   "metadata": {},
   "source": [
    "### Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caf5801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleLinearRegression(N, LAMBD)\n",
    "model.copy_params(TFModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a46639e",
   "metadata": {},
   "source": [
    "## Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3613e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(tensor_true, tensor_pred) -> float:\n",
    "    \"\"\"\n",
    "     Calculates the percentage error between two tensors or floats.\n",
    "\n",
    "     If the arguments are simple floats or ints, calculate the percentage error between them.\n",
    "     If the arguments are Numpy ndarray and PyTorch tensor, calculate the percentage error between them.\n",
    "     If the argumens are PyTorch tensors, calculate the percentage error between them.\n",
    "\n",
    "     Args:\n",
    "         tensor_true: The true tensor or true float.\n",
    "         pred_tensor: The predicted tensor or the predicted float.\n",
    "\n",
    "     Returns:\n",
    "         The percentage error between the tensors or floats.\n",
    "     \"\"\"\n",
    "    if isinstance(tensor_true, (float, int)) and isinstance(tensor_pred, (float, int)):\n",
    "        return np.abs(tensor_true - tensor_pred) / np.abs(tensor_true) * 100\n",
    "    elif type(tensor_true) is np.ndarray and type(tensor_pred) is torch.Tensor:\n",
    "        e = np.abs(tensor_true[:,0] - tensor_pred.numpy()) / np.abs(tensor_true[:,0])\n",
    "        return np.mean(e) * 100\n",
    "    e = torch.abs(tensor_true - tensor_pred) / torch.abs(tensor_true)\n",
    "    return torch.mean(e) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de91856",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea75d0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.2794064997109579e-14"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_predict = TFModel.predict(X_train, batch_size=len(X_train))\n",
    "predict = model.predict(X_train)\n",
    "\n",
    "error(tf_predict, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde36cd",
   "metadata": {},
   "source": [
    "### MSE without regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86dc012e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 8026.1792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0004926256535809091"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_predict = TFModel.evaluate(X_train, Y_train, batch_size=len(X_train))\n",
    "predict = model.evaluate(X_train, Y_train)\n",
    "\n",
    "error(tf_predict, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b2653f",
   "metadata": {},
   "source": [
    "### MSE with regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "426a3e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - loss: 8026.1792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_predict = TFModel.evaluate(X_train, Y_train, batch_size=len(X_train))\n",
    "predict = model.weight_decay_loss(X_train, Y_train)\n",
    "\n",
    "error(tf_predict, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc2591",
   "metadata": {},
   "source": [
    "### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe847ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 7540.0088 - val_loss: 13256.6025\n",
      "Epoch 2/6\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7465.1602 - val_loss: 13135.8115\n",
      "Epoch 3/6\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7391.1411 - val_loss: 13016.1553\n",
      "Epoch 4/6\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 7317.9414 - val_loss: 12897.6221\n",
      "Epoch 5/6\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 7245.5508 - val_loss: 12780.2021\n",
      "Epoch 6/6\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 7173.9590 - val_loss: 12663.8848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a769cea050>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFModel.fit(X_train, Y_train, batch_size=BATCH, epochs=EPOCHS,\n",
    "            shuffle=False, validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50d19532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - MSE_v: 13256.6023\n",
      "epoch: 1 - MSE_v: 13135.8117\n",
      "epoch: 2 - MSE_v: 13016.1553\n",
      "epoch: 3 - MSE_v: 12897.6225\n",
      "epoch: 4 - MSE_v: 12780.2025\n",
      "epoch: 5 - MSE_v: 12663.8848\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, EPOCHS, LR, BATCH, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ea3e6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4091358617918735e-15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_predict = TFModel.weights[0].numpy()\n",
    "predict = model.w\n",
    "\n",
    "error(tf_predict, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d2ab2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_predict = TFModel.weights[1].numpy()[0]\n",
    "predict = model.b.item()\n",
    "\n",
    "error(tf_predict, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a33cd2",
   "metadata": {},
   "source": [
    "# Diferents $\\lambda$ case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee97090",
   "metadata": {},
   "source": [
    "## creating 3 models with same parameters initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f464499e",
   "metadata": {},
   "source": [
    "Models\n",
    "1. Underfitting (Excesive $\\lambda$)\n",
    "2. Appropiate weight decay (Medium $\\lambda$)\n",
    "3. Overfitting ($\\lambda \\rightarrow 0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78fde4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
