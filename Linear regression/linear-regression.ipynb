{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "65f07af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "tf.keras.config.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "256a4eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_class(Class):  \n",
    "    \"\"\"Register functions as methods in created class.\"\"\"\n",
    "    def wrapper(obj):\n",
    "        setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4507c5",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86a853a",
   "metadata": {},
   "source": [
    "Dataset\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{X} &\\in \\mathbb{R}^{M \\times N} \\\\\n",
    "\\mathbf{y} &\\in \\mathbb{R}^{M}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78a6eef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "(100,)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import random\n",
    "\n",
    "M: int = 100 #number of samples\n",
    "N: int = 4 #number of features\n",
    "\n",
    "TRUE_B = random.random()\n",
    "\n",
    "X, Y, TRUE_W = make_regression(n_samples=M, n_features=N, n_targets=1,\n",
    "                               n_informative=N-1, bias=TRUE_B, noise=1, coef=True)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "print(TRUE_W.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000c71b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0a72ed",
   "metadata": {},
   "source": [
    "## weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6daab31c",
   "metadata": {},
   "source": [
    "Trainables parameters\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{w} &\\in \\mathbb{R}^{N} \\\\\n",
    "b &\\in \\mathbb{R}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac7b8024",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinearRegression:\n",
    "    def __init__(self, num_features: int) -> None:\n",
    "        self.w = torch.randn(num_features)\n",
    "        self.b = torch.randn(1)\n",
    "\n",
    "    def copy_params(self, tf_model) -> None:\n",
    "        \"\"\"Copy the parameters from a TensorFlow model to this PyTorch model.\n",
    "\n",
    "        Args:\n",
    "            tf_model: A TensorFlow model from which to copy the parameters.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        self.w.copy_(torch.tensor(tf_model.weights[0].numpy()[:,0]))\n",
    "        self.b.copy_(torch.tensor(tf_model.weights[1].numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c084d321",
   "metadata": {},
   "source": [
    "## weighted sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeb79fa",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{\\hat{y}}(\\mathbf{X}) = \\mathbf{X}\\mathbf{w} + b \\\\\n",
    "\\mathbf{\\hat{y}} : \\mathbb{R}^{M \\times N} \\rightarrow \n",
    "\\mathbb{R}^{M}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de7d50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(SimpleLinearRegression)\n",
    "def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Predict the output for input x.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor of shape (n_samples, num_features).\n",
    "\n",
    "    Returns:\n",
    "        y_pred: Predicted output tensor of shape (n_samples,).\n",
    "    \"\"\"\n",
    "    y_pred = torch.matmul(x, self.w) + self.b\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa373d19",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e377633",
   "metadata": {},
   "source": [
    "Loss function: Mean Squared Error:\n",
    "$$\n",
    "\\begin{align*}\n",
    "L(\\mathbf{\\hat{y}}) &= \\frac{1}{M} \\sum_{i=1}^{M}(\n",
    "    \\hat{y}_i - \\mathbf{\\mathbb{y}}_i)^{2} \\\\\n",
    "L &: \\mathbb{R}^{M} \\rightarrow \\mathbb{R}\n",
    "\\end{align*}\n",
    "$$\n",
    "Vectorized form:\n",
    "$$\n",
    "\\begin{align*}\n",
    "L(\\mathbf{\\hat{y}}) &= \\frac{1}{M} \n",
    "    \\left\\| \\mathbf{e} \\right\\|_{2}^2 \\\\\n",
    "\\mathbf{e} &:= \\mathbf{\\hat{y}} - \\mathbf{y}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0c53d64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(SimpleLinearRegression)\n",
    "def evaluate(self, x: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "    \"\"\"Evaluate the model on input x and target y_true using MSE.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor of shape (n_samples, num_features).\n",
    "        y_true: Target tensor of shape (n_samples,).\n",
    "\n",
    "    Returns:\n",
    "        loss: MSE loss between predictions and true values.\n",
    "    \"\"\"\n",
    "    y_pred = self.predict(x)\n",
    "    e = y_pred - y_true\n",
    "    loss = torch.linalg.vector_norm(e, ord=2)**2\n",
    "    return loss.item() / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa223c59",
   "metadata": {},
   "source": [
    "## Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14877a3c",
   "metadata": {},
   "source": [
    "Using **Numerator layout notation**.\n",
    "Gradient descent is:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{w}} =\n",
    "\\frac{\\partial L}{\\partial \\mathbf{\\hat{y}}}\n",
    "\\frac{\\partial \\mathbf{\\hat{y}}}{\\partial \\mathbf{w}}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b} =\n",
    "\\frac{\\partial L}{\\partial \\mathbf{\\hat{y}}}\n",
    "\\frac{\\partial \\mathbf{\\hat{y}}}{\\partial b}\n",
    "$$\n",
    "where their shaper are:\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{w}} \\in \\mathbb{R}^{N},\n",
    "\\frac{\\partial L}{\\partial b} \\in \\mathbb{R},\n",
    "\\frac{\\partial L}{\\partial \\mathbf{\\hat{y}}} \\in \\mathbb{R}^{M},\n",
    "\\frac{\\partial \\mathbf{\\hat{y}}}{\\partial \\mathbf{w}} \\in \\mathbb{R}^{M \\times N},\n",
    "\\frac{\\partial \\mathbf{\\hat{y}}}{\\partial b} \\in \\mathbb{R}^{M}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6ceb3",
   "metadata": {},
   "source": [
    "### weighted sum derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46842357",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{\\hat{y}} &= \\mathbf{X} \\mathbf{w} + b \\\\\n",
    "&= \\begin{bmatrix}\n",
    "        \\mathbf{x}_{1}^{T} \\\\\n",
    "        \\mathbf{x}_{2}^{T} \\\\\n",
    "        \\vdots \\\\\n",
    "        \\mathbf{x}_{M}^{T} \\\\\n",
    "    \\end{bmatrix} \\mathbf{w} + b \\\\\n",
    "&= \\begin{bmatrix}\n",
    "        \\mathbf{x}_{1}^{T} \\mathbf{w} + b \\\\\n",
    "        \\mathbf{x}_{2}^{T} \\mathbf{w} + b \\\\\n",
    "        \\vdots \\\\\n",
    "        \\mathbf{x}_{M}^{T} \\mathbf{w} + b \\\\\n",
    "    \\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\mathbf{x}_{i}^{T} = \\begin{bmatrix}\n",
    "        x_{i1} & x_{i2} & \\cdots & x_{iN}\n",
    "    \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f2219",
   "metadata": {},
   "source": [
    "#### respect to $b$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c7b02a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathbf{\\hat{y}}}{\\partial b} &= \\begin{bmatrix}\n",
    "    \\frac{\\partial \\hat{y}_{1}}{\\partial b} \\\\\n",
    "    \\frac{\\partial \\hat{y}_{2}}{\\partial b} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\frac{\\partial \\hat{y}_{M}}{\\partial b} \\\\\n",
    "\\end{bmatrix} \\in \\mathbb{R}^{M} \\\\\n",
    "&= \\boldsymbol{1} \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff33ed9",
   "metadata": {},
   "source": [
    "#### respecto to $\\mathbf{w}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c46109",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathbf{\\hat{y}}}{\\partial \\mathbf{w}} = \n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial \\hat{y}_{1}}{\\partial w_{1}} &\n",
    "    \\frac{\\partial \\hat{y}_{1}}{\\partial w_{2}} &\n",
    "    \\cdots &\n",
    "    \\frac{\\partial \\hat{y}_{1}}{\\partial w_{N}} \\\\\n",
    "    \\frac{\\partial \\hat{y}_{2}}{\\partial w_{1}} &\n",
    "    \\frac{\\partial \\hat{y}_{2}}{\\partial w_{2}} &\n",
    "    \\cdots &\n",
    "    \\frac{\\partial \\hat{y}_{2}}{\\partial w_{N}} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{\\partial \\hat{y}_{M}}{\\partial w_{1}} &\n",
    "    \\frac{\\partial \\hat{y}_{M}}{\\partial w_{2}} &\n",
    "    \\cdots &\n",
    "    \\frac{\\partial \\hat{y}_{M}}{\\partial w_{N}} \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\hat{y}_{i}}{\\partial w_{j}} &=\n",
    "\\frac{\\partial}{\\partial w_{j}} \\left(\n",
    "    x_{i1}w_{1} + x_{i2}w_{2} + \n",
    "    \\cdots + x_{ij}w_{j} + \\cdots +\n",
    "    x_{iN}w_{N}\n",
    "\\right) \\\\\n",
    "&= x_{ij}\n",
    "\\end{align*}\n",
    "$$\n",
    "therefore\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathbf{\\hat{y}}}{\\partial \\mathbf{w}} &= \n",
    "\\begin{bmatrix}\n",
    "    x_{11} & x_{12} & \\cdots & x_{1N} \\\\\n",
    "    x_{21} & x_{22} & \\cdots & x_{2N} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{M1} & x_{M2} & \\cdots & x_{MN} \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "&= \\mathbf{X}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70609520",
   "metadata": {},
   "source": [
    "### MSE derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75368993",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{\\hat{y}}} =\n",
    "\\frac{\\partial L}{\\partial \\mathbf{e}}\n",
    "\\frac{\\partial \\mathbf{e}}{\\partial \\mathbf{\\hat{y}}}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{e}} \\in \\mathbb{R}^{M},\n",
    "\\frac{\\partial \\mathbf{e}}{\\partial \\mathbf{\\hat{y}}} \\in \\mathbb{R}^{M \\times M}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec9f9f9",
   "metadata": {},
   "source": [
    "#### respecto to $\\mathbf{e}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69113ef7",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "L &= \\frac{1}{M} \\left\\| \\mathbf{e} \\right\\|_{2}^{2} \\\\\n",
    "&= \\frac{1}{M} \\left( \\mathbf{e}^{T} \\mathbf{e} \\right) \\\\\n",
    "&= \\frac{1}{M} \\left( e_{1}^{2} + e_{2}^{2} + \\cdots + e_{M}^{2} \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "then\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial \\mathbf{e}} &= \\begin{bmatrix}\n",
    "    \\frac{\\partial L}{\\partial e_{1}} &\n",
    "    \\frac{\\partial L}{\\partial e_{2}} &\n",
    "    \\cdots &\n",
    "    \\frac{\\partial L}{\\partial e_{M}} \\\\\n",
    "\\end{bmatrix}^*\n",
    "\\end{align*}\n",
    "$$\n",
    "***Remark**: This looks like a matrix (or row vector) of shape $\\mathbb{R}^{1 \\times M}$, but the first axis does not add new information, therefore we drop this axis.\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial \\mathbf{e}} &= \\begin{bmatrix}\n",
    "    \\frac{\\partial L}{\\partial e_{1}} &\n",
    "    \\frac{\\partial L}{\\partial e_{2}} &\n",
    "    \\cdots &\n",
    "    \\frac{\\partial L}{\\partial e_{M}} \\\\\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial L}{\\partial e_{1}} \\\\\n",
    "    \\frac{\\partial L}{\\partial e_{2}} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\frac{\\partial L}{\\partial e_{M}} \\\\\n",
    "\\end{bmatrix} \\in \\mathbb{R}^{M}\n",
    "\\end{align*}\n",
    "$$\n",
    "therefore\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial \\mathbf{e}} &= \\frac{2}{M} \\begin{bmatrix}\n",
    "    e_{1} \\\\\n",
    "    e_{2} \\\\\n",
    "    \\vdots \\\\\n",
    "    e_{M}\n",
    "\\end{bmatrix} \\\\\n",
    "&= \\frac{2}{M} \\mathbf{e}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b88dfeb",
   "metadata": {},
   "source": [
    "#### respect to $\\mathbf{\\hat{y}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea2882",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{e} &= \\begin{bmatrix}\n",
    "    \\hat{y}_{1} - y_{1} \\\\\n",
    "    \\hat{y}_{2} - y_{2} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\hat{y}_{M} - y_{M}\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "$$\n",
    "then\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\mathbf{e}}{\\partial \\mathbf{\\hat{y}}} &= \\begin{bmatrix}\n",
    "    \\frac{\\partial e_{1}}{\\partial \\hat{y}_{1}} &\n",
    "    \\frac{\\partial e_{1}}{\\partial \\hat{y}_{2}} &\n",
    "    \\cdots &\n",
    "    \\frac{\\partial e_{1}}{\\partial \\hat{y}_{M}} \\\\\n",
    "    \\frac{\\partial e_{2}}{\\partial \\hat{y}_{1}} &\n",
    "    \\frac{\\partial e_{2}}{\\partial \\hat{y}_{2}} &\n",
    "    \\cdots &\n",
    "    \\frac{\\partial e_{2}}{\\partial \\hat{y}_{M}} \\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{\\partial e_{M}}{\\partial \\hat{y}_{1}} &\n",
    "    \\frac{\\partial e_{M}}{\\partial \\hat{y}_{2}} &\n",
    "    \\cdots &\n",
    "    \\frac{\\partial e_{M}}{\\partial \\hat{y}_{M}} \\\\\n",
    "\\end{bmatrix} \\\\\n",
    "&= \\boldsymbol{I}\n",
    "\\end{align*}\n",
    "$$\n",
    "because the ith row of $\\mathbf{e}$ only depends on the ith row of $\\mathbf{y}$, it does not depend on any other row of $\\mathbf{y}$.\n",
    "$$\n",
    "\\frac{\\partial e_{i}}{\\partial \\hat{y}_{j}} = \\begin{cases}\n",
    "    1 & \\text{ if } i=j \\\\\n",
    "    0 & \\text{ if } i \\neq j\\\\\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d2cc85",
   "metadata": {},
   "source": [
    "#### MSE derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e44d354",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial L}{\\partial \\mathbf{\\hat{y}}} &=\n",
    "{\\color{cyan}\\frac{\\partial L}{\\partial \\mathbf{e}}}\n",
    "{\\color{orange}\\frac{\\partial \\mathbf{e}}{\\partial \\mathbf{\\hat{y}}}} \\\\\n",
    "&= {\\color{cyan}\\frac{2}{M} \\mathbf{e}}\n",
    "{\\color{orange}\\boldsymbol{I}} \\\\\n",
    "&= {\\color{cyan}\\frac{2}{M} (\\mathbf{\\hat{y}} - \\mathbf{y})}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91133e77",
   "metadata": {},
   "source": [
    "### summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0603ba7b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\nabla_{\\mathbf{w}} L =\n",
    "\\frac{\\partial L}{\\partial \\mathbf{w}} &=\n",
    "{\\color{cyan}\\frac{\\partial L}{\\partial \\mathbf{\\hat{y}}}}\n",
    "{\\color{orange}\\frac{\\partial \\mathbf{\\hat{y}}}{\\partial \\mathbf{w}}} \\\\\n",
    "&= {\\color{cyan}\\frac{2}{M} (\\mathbf{\\hat{y}} - \\mathbf{y})}\n",
    "{\\color{orange}\\mathbf{X}}\n",
    "\\end{align*}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\nabla_{b} L =\n",
    "\\frac{\\partial L}{\\partial b} &=\n",
    "{\\color{cyan}\\frac{\\partial L}{\\partial \\mathbf{\\hat{y}}}}\n",
    "{\\color{magenta}\\frac{\\partial \\mathbf{\\hat{y}}}{\\partial b}} \\\\\n",
    "&= {\\color{cyan}\\frac{2}{M} (\\mathbf{\\hat{y}} - \\mathbf{y})}\n",
    "{\\color{magenta}\\boldsymbol{1}}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434f8839",
   "metadata": {},
   "source": [
    "## Parameters update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a199a29d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{w} &\\leftarrow \\mathbf{w} - \\eta \\nabla_{\\mathbf{w}} L =\n",
    "\\mathbf{w} - \\eta \\left(\n",
    "    \\frac{2}{M} (\\mathbf{\\hat{y}} - \\mathbf{y}) \\mathbf{X}\n",
    "\\right) \\\\\n",
    "b &\\leftarrow b - \\eta \\nabla_{b} L =\n",
    "b - \\eta \\left(\n",
    "    \\frac{2}{M} (\\mathbf{\\hat{y}} - \\mathbf{y}) \\boldsymbol{1}\n",
    "\\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf504357",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(SimpleLinearRegression)\n",
    "def update(self, x: torch.Tensor, y_true: torch.Tensor,\n",
    "           y_pred: torch.Tensor, lr: float) -> None:\n",
    "    \"\"\"Update the model parameters.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor of shape (n_samples, num_features).\n",
    "        y_true: Target tensor of shape (n_samples,).\n",
    "        y_pred: Predicted output tensor of shape (n_samples,).\n",
    "        lr: Learning rate.\n",
    "    \"\"\"\n",
    "    delta = 2 * (y_pred - y_true) / len(y_true)\n",
    "    self.w -= lr * torch.matmul(delta, x)\n",
    "    #self.b -= lr * torch.dot(delta, torch.ones_like(y_true))\n",
    "    self.b -= lr * delta.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b584448d",
   "metadata": {},
   "source": [
    "## Fit (Gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa10e064",
   "metadata": {},
   "source": [
    "We have assumed that we will use the entire dataset to update our parameters, \n",
    "but we can use only a fraction of the observations/examples in our dataset to update our parameters. <br>\n",
    "There are mainly 3 ways to use Gradient descent (GD).\n",
    "- batch GD\n",
    "- stochastic GD (SGD)\n",
    "- mini-batch GD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6cc9d4",
   "metadata": {},
   "source": [
    "### batch GD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf7c5d5",
   "metadata": {},
   "source": [
    "The batch GD uses all observations/examples to update our parameters:\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\textbf{Algorithm 1: batch Gradient Descent} \\\\\n",
    "\\textbf{for } t = 1 \\text{ to } T \\textbf{ do}\\\\\n",
    "\\quad \\mathbf{\\theta} \\leftarrow \\text{update}(\\mathbf{X}, \\mathbf{y}; \\mathbf{\\theta}) \\\\\n",
    "\\textbf{end for}\n",
    "\\end{array}\n",
    "$$\n",
    "where $T$ is the number of epochs. <br>\n",
    "**Remark**: $\\mathbf{\\theta}$ is an arbitrary parameter, for this model we have to update $\\mathbf{w}$ and $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cd9bb8",
   "metadata": {},
   "source": [
    "### stochastic GD (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7f9c81",
   "metadata": {},
   "source": [
    "The SGD for each epoch, we update our parameters for each observation/example that is in our dataset:\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\textbf{Algorithm 2: stochastic Gradient Descent (SGD)} \\\\\n",
    "\\textbf{for } t = 1 \\text{ to } T \\textbf{ do}\\\\\n",
    "\\quad \\textbf{for } m = 1 \\text{ to } M \\textbf{ do} \\\\\n",
    "\\quad \\quad \\mathbf{\\theta} \\leftarrow \\text{update}(\\mathbf{X}_{m,:}, \\mathbf{y}_{m,:}; \\mathbf{\\theta}) \\\\\n",
    "\\textbf{end for}\n",
    "\\end{array}\n",
    "$$\n",
    "where $\\mathbf{X}_{m,:}$ and $\\mathbf{y}_{m,:}$ are the mth observation/example of our dataset. <br>\n",
    "**Note**: $\\mathbf{X}_{m,:} \\in \\mathbb{R}^{1 \\times N}$ and $\\mathbf{y}_{m,:} \\in \\mathbb{R}^{1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bf8b61",
   "metadata": {},
   "source": [
    "### mini-batch GD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddce954",
   "metadata": {},
   "source": [
    "The mini-batch GD is intermediate between SGD and batch GD since a fragment of \n",
    "the dataset larger than SGD but smaller than batch GD is used to update our parameters per epoch:\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "\\textbf{Algorithm 3: mini-batch Gradient Descent} \\\\\n",
    "\\textbf{for } t = 1 \\text{ to } T \\textbf{ do} \\\\\n",
    "\\quad m \\leftarrow 1 \\\\\n",
    "\\quad \\tilde{m} \\leftarrow \\mathcal{B} \\\\\n",
    "\\quad \\textbf{while } m < M \\textbf{ do} \\\\\n",
    "\\quad \\quad \\mathbf{\\theta} \\leftarrow \\text{update}(\\mathbf{X}_{m:\\tilde{m},:}, \\mathbf{y}_{m:\\tilde{m},:}; \\mathbf{\\theta}) \\\\\n",
    "\\quad \\quad m \\leftarrow m + \\mathcal{B} \\\\\n",
    "\\quad \\quad \\tilde{m} \\leftarrow \\tilde{m} + \\mathcal{B} \\\\\n",
    "\\textbf{end for}\n",
    "\\end{array}\n",
    "$$\n",
    "where $\\mathcal{B}$ is the number of minibatch that we want. <br>\n",
    "where $\\mathbf{X}_{m:\\tilde{m},:}$ and $\\mathbf{y}_{m:\\tilde{m},:}$ are the $m$-th to $\\tilde{m}$-th observations/examples. <br>\n",
    "**Note**: If $\\mathcal{B}=1$, then mini-batch GD becomes SGD. \n",
    "And if $\\mathcal{B}=M$, then mini-batch GD becomes batch GD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7841483",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(SimpleLinearRegression)\n",
    "def fit(self, x_train: torch.Tensor, y_train: torch.Tensor, \n",
    "        epochs: int, lr: float, batch_size: int, \n",
    "        x_valid: torch.Tensor, y_valid: torch.Tensor) -> None:\n",
    "    \"\"\"fit the model using gradient descent.\n",
    "\n",
    "    Args:\n",
    "        x_train: Input tensor of shape (n_samples, num_features).\n",
    "        y_train: Target tensor of shape (n_samples,).\n",
    "        epochs: Number of epochs to train.\n",
    "        lr: learning rate (0, 1).\n",
    "        batch_size: Int number of batch.\n",
    "        x_valid: Input tensor of shape (n_valid_samples, num_features).\n",
    "        y_valid: Input tensor of shape (n_valid_samples,).\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        num_batch = 0\n",
    "        for batch in range(0, len(y_train), batch_size):\n",
    "            num_batch += 1\n",
    "            x_b = x_train[batch:batch+batch_size]\n",
    "            y_b = y_train[batch:batch+batch_size]\n",
    "\n",
    "            y_pred = self.predict(x_b)\n",
    "            loss += self.evaluate(x_b, y_b)\n",
    "\n",
    "            self.update(x_b, y_b, y_pred, lr)\n",
    "\n",
    "        loss = round(loss / num_batch, 4)\n",
    "        loss_v = round(self.evaluate(x_valid, y_valid), 4)\n",
    "        print(f'epoch: {epoch} - MSE: {loss} - MSE_v: {loss_v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186b36c2",
   "metadata": {},
   "source": [
    "# Scratch vs TF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7757178b",
   "metadata": {},
   "source": [
    "## Train and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "511a0e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([85, 4]) torch.Size([85])\n",
      "torch.Size([15, 4]) torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = torch.tensor(X[:85]), torch.tensor(Y[:85])\n",
    "X_valid, Y_valid = torch.tensor(X[85:]), torch.tensor(Y[85:])\n",
    "\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_valid.shape, Y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770577f6",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1c5520aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.001\n",
    "EPOCHS = 6\n",
    "BATCH = len(X_train) // 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439927e7",
   "metadata": {},
   "source": [
    "## models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526b77ab",
   "metadata": {},
   "source": [
    "### TF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37c856b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - loss: 40809.1172\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> (40.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5\u001b[0m (40.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> (40.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5\u001b[0m (40.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TFModel = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, activation='linear')\n",
    "])\n",
    "\n",
    "TFModel.compile(\n",
    "    loss = tf.keras.losses.MSE,\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=LR)\n",
    ")\n",
    "\n",
    "TFModel.evaluate(X[:1], Y[:1])\n",
    "\n",
    "TFModel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ce0d06",
   "metadata": {},
   "source": [
    "### Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "caf5801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleLinearRegression(N)\n",
    "model.copy_params(TFModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a46639e",
   "metadata": {},
   "source": [
    "## Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3613e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(tensor_true, tensor_pred) -> float:\n",
    "    \"\"\"\n",
    "     Calculates the percentage error between two tensors or floats.\n",
    "\n",
    "     If the arguments are simple floats or ints, calculate the percentage error between them.\n",
    "     If the arguments are Numpy ndarray and PyTorch tensor, calculate the percentage error between them.\n",
    "     If the argumens are PyTorch tensors, calculate the percentage error between them.\n",
    "\n",
    "     Args:\n",
    "         tensor_true: The true tensor or true float.\n",
    "         pred_tensor: The predicted tensor or the predicted float.\n",
    "\n",
    "     Returns:\n",
    "         The percentage error between the tensors or floats.\n",
    "     \"\"\"\n",
    "    if isinstance(tensor_true, (float, int)) and isinstance(tensor_pred, (float, int)):\n",
    "        return np.abs(tensor_true - tensor_pred) / np.abs(tensor_true) * 100\n",
    "    elif type(tensor_true) is np.ndarray and type(tensor_pred) is torch.Tensor:\n",
    "        e = np.abs(tensor_true[:,0] - tensor_pred.numpy()) / np.abs(tensor_true[:,0])\n",
    "        return np.mean(e) * 100\n",
    "    e = torch.abs(tensor_true - tensor_pred) / torch.abs(tensor_true)\n",
    "    return torch.mean(e) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de91856",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ea75d0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.650808568743399e-14"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_predict = TFModel.predict(X_train, batch_size=len(X_train))\n",
    "predict = model.predict(X_train)\n",
    "\n",
    "error(tf_predict, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fde36cd",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86dc012e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 16131.5088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.382800883432671e-14"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_predict = TFModel.evaluate(X_train, Y_train, batch_size=len(X_train))\n",
    "predict = model.evaluate(X_train, Y_train)\n",
    "\n",
    "error(tf_predict, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fc2591",
   "metadata": {},
   "source": [
    "### fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe847ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 14411.8545 - val_loss: 16204.4268\n",
      "Epoch 2/6\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 14255.2051 - val_loss: 16088.6729\n",
      "Epoch 3/6\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 14100.7217 - val_loss: 15973.4121\n",
      "Epoch 4/6\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13948.3633 - val_loss: 15858.6504\n",
      "Epoch 5/6\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13798.0869 - val_loss: 15744.3896\n",
      "Epoch 6/6\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 13649.8555 - val_loss: 15630.6338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2116c6d2e50>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFModel.fit(X_train, Y_train, batch_size=BATCH, epochs=EPOCHS,\n",
    "            shuffle=False, validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5df101e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12944.80773781999,\n",
       " 12791.005804509703,\n",
       " 12639.642102655596,\n",
       " 12490.66350789638,\n",
       " 12344.018326801,\n",
       " 12199.656254338679]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFModel.history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "50d19532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - MSE: 12944.8077 - MSE_v: 16204.4264\n",
      "epoch: 1 - MSE: 12791.0058 - MSE_v: 16088.6725\n",
      "epoch: 2 - MSE: 12639.6421 - MSE_v: 15973.4124\n",
      "epoch: 3 - MSE: 12490.6635 - MSE_v: 15858.65\n",
      "epoch: 4 - MSE: 12344.0183 - MSE_v: 15744.3893\n",
      "epoch: 5 - MSE: 12199.6563 - MSE_v: 15630.6339\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, EPOCHS, LR, BATCH, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9ea3e6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_predict = TFModel.weights[0].numpy()\n",
    "predict = model.w\n",
    "\n",
    "error(tf_predict, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d2ab2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_predict = TFModel.weights[1].numpy()[0]\n",
    "predict = model.b.item()\n",
    "\n",
    "error(tf_predict, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a33cd2",
   "metadata": {},
   "source": [
    "# Full train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee2043af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5672])\n",
      "tensor([ 0.8851,  0.0267, -0.2394,  1.3298])\n"
     ]
    }
   ],
   "source": [
    "model2 = SimpleLinearRegression(N)\n",
    "\n",
    "print(model2.b)\n",
    "print(model2.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f4df8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16355.892941456297"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "080ef67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99.45714892299446, 726.8472640135958)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(TRUE_W[None,:] + 1e-100, model2.w + 1e-100), error(TRUE_B, model2.b.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1b7e5e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - MSE: 14104.3652 - MSE_v: 12716.8702\n",
      "epoch: 1 - MSE: 10658.6472 - MSE_v: 9897.6332\n",
      "epoch: 2 - MSE: 8106.0311 - MSE_v: 7709.0072\n",
      "epoch: 3 - MSE: 6197.727 - MSE_v: 6007.5814\n",
      "epoch: 4 - MSE: 4759.9822 - MSE_v: 4683.6717\n",
      "epoch: 5 - MSE: 3669.6193 - MSE_v: 3652.8621\n",
      "epoch: 6 - MSE: 2838.1062 - MSE_v: 2849.9034\n",
      "epoch: 7 - MSE: 2201.0192 - MSE_v: 2224.2168\n",
      "epoch: 8 - MSE: 1710.9636 - MSE_v: 1736.5232\n",
      "epoch: 9 - MSE: 1332.7393 - MSE_v: 1356.2843\n",
      "epoch: 10 - MSE: 1039.9887 - MSE_v: 1059.7408\n",
      "epoch: 11 - MSE: 812.8367 - MSE_v: 828.4007\n",
      "epoch: 12 - MSE: 636.2072 - MSE_v: 647.8683\n",
      "epoch: 13 - MSE: 498.6064 - MSE_v: 506.9349\n",
      "epoch: 14 - MSE: 391.2338 - MSE_v: 396.8726\n",
      "epoch: 15 - MSE: 307.3263 - MSE_v: 310.8841\n",
      "epoch: 16 - MSE: 241.67 - MSE_v: 243.6749\n",
      "epoch: 17 - MSE: 190.2344 - MSE_v: 191.1204\n",
      "epoch: 18 - MSE: 149.8963 - MSE_v: 150.0064\n",
      "epoch: 19 - MSE: 118.2306 - MSE_v: 117.8274\n",
      "epoch: 20 - MSE: 93.3507 - MSE_v: 92.6298\n",
      "epoch: 21 - MSE: 73.7865 - MSE_v: 72.8898\n",
      "epoch: 22 - MSE: 58.3906 - MSE_v: 57.4182\n",
      "epoch: 23 - MSE: 46.2666 - MSE_v: 45.2865\n",
      "epoch: 24 - MSE: 36.713 - MSE_v: 35.7694\n",
      "epoch: 25 - MSE: 29.1803 - MSE_v: 28.3004\n",
      "epoch: 26 - MSE: 23.2379 - MSE_v: 22.4361\n",
      "epoch: 27 - MSE: 18.5476 - MSE_v: 17.8301\n",
      "epoch: 28 - MSE: 14.8438 - MSE_v: 14.211\n",
      "epoch: 29 - MSE: 11.9177 - MSE_v: 11.3663\n",
      "epoch: 30 - MSE: 9.6051 - MSE_v: 9.1296\n",
      "epoch: 31 - MSE: 7.7767 - MSE_v: 7.3705\n",
      "epoch: 32 - MSE: 6.3306 - MSE_v: 5.9865\n",
      "epoch: 33 - MSE: 5.1864 - MSE_v: 4.8974\n",
      "epoch: 34 - MSE: 4.2809 - MSE_v: 4.0401\n",
      "epoch: 35 - MSE: 3.564 - MSE_v: 3.3653\n",
      "epoch: 36 - MSE: 2.9964 - MSE_v: 2.8339\n",
      "epoch: 37 - MSE: 2.5468 - MSE_v: 2.4154\n",
      "epoch: 38 - MSE: 2.1907 - MSE_v: 2.0858\n",
      "epoch: 39 - MSE: 1.9084 - MSE_v: 1.8263\n",
      "epoch: 40 - MSE: 1.6847 - MSE_v: 1.6218\n",
      "epoch: 41 - MSE: 1.5074 - MSE_v: 1.4607\n",
      "epoch: 42 - MSE: 1.3669 - MSE_v: 1.3339\n",
      "epoch: 43 - MSE: 1.2554 - MSE_v: 1.234\n",
      "epoch: 44 - MSE: 1.167 - MSE_v: 1.1553\n",
      "epoch: 45 - MSE: 1.0969 - MSE_v: 1.0933\n",
      "epoch: 46 - MSE: 1.0413 - MSE_v: 1.0445\n",
      "epoch: 47 - MSE: 0.9972 - MSE_v: 1.0061\n",
      "epoch: 48 - MSE: 0.9622 - MSE_v: 0.9759\n",
      "epoch: 49 - MSE: 0.9344 - MSE_v: 0.9521\n",
      "epoch: 50 - MSE: 0.9124 - MSE_v: 0.9335\n",
      "epoch: 51 - MSE: 0.8949 - MSE_v: 0.9188\n",
      "epoch: 52 - MSE: 0.881 - MSE_v: 0.9072\n",
      "epoch: 53 - MSE: 0.87 - MSE_v: 0.8981\n",
      "epoch: 54 - MSE: 0.8613 - MSE_v: 0.891\n",
      "epoch: 55 - MSE: 0.8543 - MSE_v: 0.8854\n",
      "epoch: 56 - MSE: 0.8488 - MSE_v: 0.8811\n",
      "epoch: 57 - MSE: 0.8445 - MSE_v: 0.8776\n",
      "epoch: 58 - MSE: 0.841 - MSE_v: 0.875\n",
      "epoch: 59 - MSE: 0.8382 - MSE_v: 0.8729\n",
      "epoch: 60 - MSE: 0.8361 - MSE_v: 0.8712\n",
      "epoch: 61 - MSE: 0.8343 - MSE_v: 0.87\n",
      "epoch: 62 - MSE: 0.8329 - MSE_v: 0.869\n",
      "epoch: 63 - MSE: 0.8319 - MSE_v: 0.8682\n",
      "epoch: 64 - MSE: 0.831 - MSE_v: 0.8676\n",
      "epoch: 65 - MSE: 0.8303 - MSE_v: 0.8671\n",
      "epoch: 66 - MSE: 0.8298 - MSE_v: 0.8668\n",
      "epoch: 67 - MSE: 0.8293 - MSE_v: 0.8665\n",
      "epoch: 68 - MSE: 0.829 - MSE_v: 0.8663\n",
      "epoch: 69 - MSE: 0.8287 - MSE_v: 0.8661\n",
      "epoch: 70 - MSE: 0.8285 - MSE_v: 0.866\n",
      "epoch: 71 - MSE: 0.8283 - MSE_v: 0.8659\n",
      "epoch: 72 - MSE: 0.8282 - MSE_v: 0.8658\n",
      "epoch: 73 - MSE: 0.8281 - MSE_v: 0.8658\n",
      "epoch: 74 - MSE: 0.828 - MSE_v: 0.8657\n",
      "epoch: 75 - MSE: 0.8279 - MSE_v: 0.8657\n",
      "epoch: 76 - MSE: 0.8279 - MSE_v: 0.8657\n",
      "epoch: 77 - MSE: 0.8278 - MSE_v: 0.8656\n",
      "epoch: 78 - MSE: 0.8278 - MSE_v: 0.8656\n",
      "epoch: 79 - MSE: 0.8278 - MSE_v: 0.8656\n",
      "epoch: 80 - MSE: 0.8278 - MSE_v: 0.8656\n",
      "epoch: 81 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 82 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 83 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 84 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 85 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 86 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 87 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 88 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 89 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 90 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 91 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 92 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 93 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 94 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 95 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 96 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 97 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 98 - MSE: 0.8277 - MSE_v: 0.8656\n",
      "epoch: 99 - MSE: 0.8277 - MSE_v: 0.8656\n"
     ]
    }
   ],
   "source": [
    "model2.fit(X_train, Y_train, 100, 0.001, 1, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2148fb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32.90080475829641, 43.1821057699658)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error(TRUE_W[None,:] + 1e-100, model2.w + 1e-100), error(TRUE_B, model2.b.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
